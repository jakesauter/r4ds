---
title: "Modelling"
author: "Jake Sauter"
output: 
  html_document: 
    toc: true
    toc_float: true
    df_print: kable 
---

```{r global_options, include=FALSE}
knitr::opts_chunk$set(
  cache = FALSE, 
  warning = FALSE, 
  message = FALSE,
  hold = TRUE)

library(knitr)
library(kableExtra)

kable <- function(data, ...) {
  knitr::kable(data, digits=3, ...) %>% 
    kable_styling(bootstrap_options = c('striped', 
                                        'hover', 
                                        'responsive'),
                  full_width = FALSE, 
                  position = 'center', )
}

knit_print.data.frame <- function(x, ...) {
  res <- paste(c('', '', kable(head(x))), collapse = '\n')
  asis_output(res)
}

registerS3method('knit_print', 'data.frame', knit_print.data.frame)
```

# Modelling

```{r libraries}
library(tidyverse)
library(modelr)
options(na.action = na.warn)
```

```{r}
ggplot(sim1, aes(x, y)) + 
  geom_point()
```


```{r}
models <- tibble(
  a1 = runif(250, -20, 40), 
  a2 = runif(250, -5, 5)
)

ggplot(sim1, aes(x, y)) + 
  geom_abline(aes(intercept = a1, slope = a2), data = models, alpha = 1/4) + 
  geom_point()
```

```{r}
# Generate predictions given a model and data
model1 <- function(a, data) {
  a[1] + data$x * a[2]
}

model1(c(7, 1.5), sim1)
```

```{r}
# Measure the loss of a model given the model and test data 
measure_distance <- function(model, data) {
  diff <- data$y - model1(model, data)
  sqrt(mean(diff^2)) # rms deviation
}

measure_distance(c(7, 1.5), sim1)
```

```{r}
# Now we can use purrr to compute the rms deviation
# of all of our models

models <- models %>% 
  mutate(dist = purrr::map2_dbl(a1, a2, ~measure_distance(c(..1, ..2), sim1)))

models
```


Now lets overlay 10 of the best models onto the data

```{r}
ggplot(sim1, aes(x,y)) + 
  geom_point(size = 2, color = 'grey30') + 
  geom_abline(
    aes(intercept = a1, slope = a2, color = -dist), 
    data = filter(models, rank(dist) <= 10)
  )
```


Not too bad, lets take a look at the parameter space of these models
to gain some intuition about why thery are good

```{r}
ggplot(models, aes(a1, a2)) + 
  geom_point(data = filter(models, rank(dist) <= 10), size = 4, color = 'red') + 
  geom_point(aes(color = -dist))
```


## Grid Search

So it seems like the parameters are all in a similiar neighborhood
in the parameter space, lets try to grid search this space 
to get a more optimal model

```{r}
grid <- expand.grid(
  a1 = seq(-5, 20, length.out = 25), 
  a2 = seq(1, 3, length.out = 25)
) %>% 
  mutate(dist = purrr::map2_dbl(a1, a2, ~ measure_distance(c(..1, ..2), sim1)))

grid %>% 
  ggplot(aes(a1, a2)) + 
  geom_point(data = filter(grid, rank(dist) <= 10), size = 4, color = 'red') + 
  geom_point(aes(color = -dist))
```

Now lets see how these models do 

```{r}
ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, color = 'grey30') + 
  geom_abline(
    aes(intercept = a1, slope = a2, color = dist), 
    data = filter(grid, rank(dist) <= 10)
    )
```

Much better! One can see how if we iterated on this idea that we would soon fine
the line of best fit. Fortunately we do not have to implement this ourselves as it 
is implemented multiple ways across R. 

## Model Optimization

We can provide `stats::optim()` an initial parameter value as well as a loss function 
and some data in order for it to search the parameter space in an intelligent way 
for us and return the optimal parameter settings!

We can provide some fancier parameters to this function such as `gr`, which is a function
that returns gradient values for the function at a point in parameter space, but
it works just fine for small models empirically. 

```{r}
best <- stats::optim(c(0,0), measure_distance, data = sim1)
best$par

ggplot(sim1, aes(x, y)) + 
  geom_point(size = 2, color = 'gray30') + 
  geom_abline(intercept = best$par[1], slope = best$par[2])
```


As we can see this model fits the data nearly perfectly. 

Though because our model fits the general model family of models, we 
can use R's build in `base::lm()` function to find the optimal parameter
settings deterministically

```{r}
sim1_mod <- lm(y ~ x, data = sim1)
coef(sim1_mod)
best$par
```


# Visualizing Models

We can start by generating a grid of data for our model to process.

```{r}
grid <- sim1 %>% 
  data_grid(x)

grid
```

Now we can add predictions to this grid easily using the `modelr::add_predictions()` function. 

```{r}
grid <- grid %>% 
  add_predictions(sim1_mod)

grid
```

Now we can visualize these predictions. Keep in mind that this method will work for many different
model types in R unlike our simple `geom_abline()` implementation from earlier. 

```{r}
ggplot(sim1, aes(x)) + 
  geom_point(aes(y = y)) + 
  geom_line(aes(y = pred), data = grid, color = 'red', size = 1)
```


# Residuals 

Adding residuals from our model to the original dataset is also very easy using 
`modelr::add_residuals()`

```{r}
sim1 <- sim1 %>% 
  add_residuals(sim1_mod)

sim1
```


We can draw a frequecy polygram to see the distributions of residuals

```{r}
ggplot(sim1, aes(resid)) + 
  geom_freqpoly(binwidth = 0.5)
```

```{r}
ggplot(sim1, aes(x, resid)) + 
  geom_ref_line(h = 0) + 
  geom_point()
```


`modelr` provides the great `geom_ref_line()` geom so that we can see a plot of our 
residuals vs our data as is usually done in statistical model analysis. Here we see uniform
variance of our residuals, which can also be put as **homoscedasticity** of our residuals. 

# Formuals and Model Families 

Lets see how `modelr` works under the hood with `model_matrix()`. Here we see 
that `modelr` converts our formula to a data frame with each column being a model 
parameter. Note that this is not unique to `modelr` as `modelr::model_matrix()` is a 
thin wrapper around `stats::model.matrix()`.

```{r}
df <- tribble(
  ~y, ~x1, ~x2, 
   4,  2,  5, 
   5,  1,  6
)

model_matrix(df,y ~ x1)
```

By default an intercept will always be added, though we can bypass this functionality 
with the following formulation. 

```{r}
model_matrix(df, y ~ x1 - 1)
```

```{r}
model_matrix(df, y ~ x1 + x2)
```

This formula notation is sometimes called “Wilkinson-Rogers notation”, and was initially described in Symbolic Description of Factorial Models for Analysis of Variance, by G. N. Wilkinson and C. E. Rogers. 


# Categorical Variables

```{r}
df <- tribble(
 ~sex, ~response, 
 'male', 1, 
 'female', 2, 
 'male', 1
)

model_matrix(df, response ~ sex)
```
 

Notice that we only have a `sexmale` category as `sexfemale` is perfectly predictable from 
the inverse of this column. 

```{r}
ggplot(sim2) + 
  geom_point(aes(x, y))
```

Lets fit a model to this data and generate predictions. 

```{r}
model2 <- lm(y ~ x, data = sim2) 

grid <- sim2 %>% 
  data_grid(x) %>% 
  add_predictions(model2)

grid
```

Notice how the model predicts the mean of each category as it minimizes the rms distance. 

```{r}
ggplot(sim2, aes(x)) + 
  geom_point(aes(y = y)) + 
  geom_point(data = grid, aes(y = pred), color = 'red', size = 4)
```

We can't make predictions about levels that we didn't observe during training/model fitting. 

```{r, warning=TRUE}
tibble(x = 'e') %>% 
  add_predictions(mod2)
```

# Interactions (continuous and categorical)

The `modelr::sim3` dataset contains a categorical predictor and a continuous predictor. Lets
see how to handle data like this 

```{r}
ggplot(sim3, aes(x1, y)) + 
  geom_point(aes(color = x2))
```


Two possible models that can fit this data are: 

```{r}
mod1 <- lm(y ~ x1 + x2, data = sim3)
mod2 <- lm(y ~ x1 * x2, data = sim3)
```

When variables are added with `+`, the model estimates each effect independent of all others. However
it is possible 



























